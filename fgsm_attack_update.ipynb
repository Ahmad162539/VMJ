{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/VMJ/blob/main/fgsm_attack_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns4t5rH91DGX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D  # Updated import statement\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n-ZYnTS51NQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/T25 (1).csv')"
      ],
      "metadata": {
        "id": "uQlf_Ce41W6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(df['Dataset'].tolist())"
      ],
      "metadata": {
        "id": "MjY81eDq1ciP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ckvYIZRc1h-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [eval(i) for i in df['resized_scaled'].tolist()]\n",
        "X = np.array(X)\n",
        "y = np.array(df['SOH'].tolist()) ##%changed"
      ],
      "metadata": {
        "id": "X0raWgUB1kke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labeling for stratified random sampling\n",
        "label = df['SOH'].tolist()\n",
        "label_l = []\n",
        "for cnt in range(len(label)):\n",
        "    i = label[cnt]\n",
        "    if i>=1.0 :\n",
        "        lab = '1~'\n",
        "        num = 0\n",
        "    elif 0.98<=i<1.0 :\n",
        "        lab = '0.98~1'\n",
        "        num = 1\n",
        "    elif 0.96<=i<0.98 :\n",
        "        lab = '0.96~0.98'\n",
        "        num = 2\n",
        "    elif 0.94<=i<0.96 :\n",
        "        lab = '0.94~0.96'\n",
        "        num = 3\n",
        "    elif 0.92<=i<0.94 :\n",
        "        lab = '0.92~0.94'\n",
        "        num = 4\n",
        "    elif 0.90<=i<0.92 :\n",
        "        lab = '0.90~0.92'\n",
        "        num = 5\n",
        "\n",
        "    elif 0.88<=i<0.9 :\n",
        "        lab = '0.88~0.9'\n",
        "        num = 6\n",
        "    elif 0.86<=i<0.88 :\n",
        "        lab = '0.86~0.88'\n",
        "        num = 7\n",
        "    elif 0.84<=i<0.86 :\n",
        "        lab = '0.84~0.86'\n",
        "        num = 8\n",
        "    elif 0.82<=i<0.84 :\n",
        "        lab = '0.82~0.84'\n",
        "        num = 9\n",
        "    elif 0.80<=i<0.82 :\n",
        "        lab = '0.80~0.82'\n",
        "        num = 10\n",
        "\n",
        "\n",
        "    elif 0.78<=i<0.8 :\n",
        "        lab = '0.78~0.8'\n",
        "        num = 11\n",
        "    elif 0.76<=i<0.78 :\n",
        "        lab = '0.76~0.78'\n",
        "        num = 12\n",
        "    elif 0.74<=i<0.76 :\n",
        "        lab = '0.74~0.76'\n",
        "        num = 13\n",
        "    elif 0.72<=i<0.74 :\n",
        "        lab = '0.72~0.74'\n",
        "        num = 14\n",
        "    elif 0.70<=i<0.72 :\n",
        "        lab = '0.70~0.72'\n",
        "        num = 15\n",
        "\n",
        "    else:\n",
        "        lab = '~0.7'\n",
        "        num = 16\n",
        "    label_l.append(num)"
      ],
      "metadata": {
        "id": "hBPXjryt1slu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
        "for train_idx, test_idx in sss.split(X, np.array(label_l)):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = np.array(y)[train_idx], np.array(y)[test_idx]\n",
        "    y_valid = np.array(label_l)[test_idx]"
      ],
      "metadata": {
        "id": "HKuuEx9laE0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
        "for train_idx, test_idx1 in sss.split(X_test, y_valid):\n",
        "    X_valid, X_test_f = X_test[train_idx], X_test[test_idx1]\n",
        "    y_valid, y_test_f = np.array(y_test)[train_idx], np.array(y_test)[test_idx1]\n",
        "X_valid.shape\n"
      ],
      "metadata": {
        "id": "eErr4p7MlqeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for i in df['Dataset'][test_idx[test_idx1]].tolist():\n",
        "    if 'LFP' in i:\n",
        "        data_list.append('LFP')\n",
        "    if 'NCA' in i:\n",
        "        data_list.append('NCA')\n",
        "    if 'NMC' in i:\n",
        "        data_list.append('NMC')"
      ],
      "metadata": {
        "id": "qXA634s1l40g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = X_train\n",
        "x_valid = X_valid\n",
        "x_test = X_test_f"
      ],
      "metadata": {
        "id": "MkNZ5HYal71g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = len(X[0])\n",
        "cols = 3\n",
        "input_shape = (rows, cols, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], rows, cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32') /255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_valid = x_valid.astype('float32')/255.0\n",
        "\n",
        "batch_size = 64\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "5UGCykMal_Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(Conv2D(64, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), strides = (1,1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "###"
      ],
      "metadata": {
        "id": "gXV2e3kP2pPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "epochs = 5\n",
        "print('start time : ' , start)\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])\n",
        "hist2 = model.fit(x_train, y_train, epochs = epochs, verbose = 1, validation_data = (x_valid, y_valid))"
      ],
      "metadata": {
        "id": "9XJbKJvT2sn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = hist2.history['val_loss']\n",
        "y_loss = hist2.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.legend()\n",
        "plt.title('epoch40_loss')"
      ],
      "metadata": {
        "id": "gV7i8S7m2w7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(x_test, verbose = 0)"
      ],
      "metadata": {
        "id": "88O3lI3d6Vi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "t = []\n",
        "for i in range(len(predict)):\n",
        "    p.append(predict[i])\n",
        "    t.append(y_test_f[i])\n",
        "    #print('predicted SOH: ' , predict[i],',' , 'Answer SOH: '  , y_test[i])\n",
        "\n",
        "plt.scatter(y_test_f, predict)\n",
        "plt.plot(y_test_f, y_test_f,c='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3xXBm0LF2zqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = metrics.r2_score(y_test_f, predict)\n",
        "rmse = metrics.mean_squared_error(y_test_f, predict)**0.5\n",
        "mse = metrics.mean_squared_error(y_test_f, predict)\n",
        "mae = metrics.mean_absolute_error(y_test_f, predict)\n",
        "mape = metrics.mean_absolute_percentage_error(y_test_f,predict)"
      ],
      "metadata": {
        "id": "RC1hrOQu24CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "dic['r2'] = [r2]\n",
        "dic['rmse'] = [rmse]\n",
        "dic['mse'] = [mse]\n",
        "dic['mae'] = [mae]\n",
        "dic['mape'] = [mape]\n",
        "d = pd.DataFrame(dic)\n",
        "d"
      ],
      "metadata": {
        "id": "L04LdKVM26on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/trained_model.h5')\n",
        "\n",
        "# Define the FGSM attack function\n",
        "def fgsm_attack(input_data, epsilon, model, y_test):\n",
        "    input_data = tf.convert_to_tensor(input_data)  # Convert to TensorFlow tensor\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(input_data)\n",
        "        predictions = model(input_data)\n",
        "        loss = tf.keras.losses.mean_squared_error(y_test, predictions)\n",
        "\n",
        "    gradient = tape.gradient(loss, input_data)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    adversarial_data = input_data + epsilon * signed_grad\n",
        "    return adversarial_data\n",
        "\n",
        "# Calculate the number of samples for the attack\n",
        "attack_samples = int(0.4 * len(x_test))  # 10% of the test data\n",
        "\n",
        "# Randomly select indices for the attack\n",
        "attack_indices = np.random.choice(len(x_test), attack_samples, replace=False)\n",
        "\n",
        "# Generate adversarial examples for the selected subset using FGSM\n",
        "epsilon = 0.1  # Adjust the value of epsilon as needed\n",
        "x_test_f_adversarial = x_test.copy()  # Create a copy to store adversarial examples\n",
        "x_test_f_adversarial[attack_indices] = fgsm_attack(x_test[attack_indices], epsilon, model, y_test[attack_indices])\n",
        "x_test[attack_indices]=x_test_f_adversarial[attack_indices]"
      ],
      "metadata": {
        "id": "RgpU81Mi3CHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(Conv2D(64, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), strides = (1,1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "###"
      ],
      "metadata": {
        "id": "p94GE7yK6219"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "epochs = 10\n",
        "print('start time : ' , start)\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])\n",
        "hist2 = model.fit(x_train, y_train, epochs = epochs, verbose = 1, validation_data = (x_valid, y_valid))"
      ],
      "metadata": {
        "id": "2BQLlapr65He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = hist2.history['val_loss']\n",
        "y_loss = hist2.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.legend()\n",
        "plt.title('epoch40_loss')"
      ],
      "metadata": {
        "id": "wnQsUBwS69CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(x_test, verbose = 0)"
      ],
      "metadata": {
        "id": "XTsYem767ELd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "t = []\n",
        "for i in range(len(predict)):\n",
        "    p.append(predict[i])\n",
        "    t.append(y_test_f[i])\n",
        "    #print('predicted SOH: ' , predict[i],',' , 'Answer SOH: '  , y_test[i])\n",
        "\n",
        "plt.scatter(y_test_f, predict)\n",
        "plt.plot(y_test_f, y_test_f,c='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iFpyDO8g7LzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = metrics.r2_score(y_test_f, predict)\n",
        "rmse = metrics.mean_squared_error(y_test_f, predict)**0.5\n",
        "mse = metrics.mean_squared_error(y_test_f, predict)\n",
        "mae = metrics.mean_absolute_error(y_test_f, predict)\n",
        "mape = metrics.mean_absolute_percentage_error(y_test_f,predict)"
      ],
      "metadata": {
        "id": "N1tkOXqe7PFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "dic['r2'] = [r2]\n",
        "dic['rmse'] = [rmse]\n",
        "dic['mse'] = [mse]\n",
        "dic['mae'] = [mae]\n",
        "dic['mape'] = [mape]\n",
        "d = pd.DataFrame(dic)"
      ],
      "metadata": {
        "id": "cu17nfzk7SDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "gjbdDmTq7U6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}