{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/VMJ/blob/main/newfgsmattack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BublBbu9D_-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D  # Updated import statement\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LuzlbBmiEHZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/T25 (1).csv')"
      ],
      "metadata": {
        "id": "iL4gNU7hEKOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(df['Dataset'].tolist())"
      ],
      "metadata": {
        "id": "6PUupQugEMkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Y-DFLjqbEV3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [eval(i) for i in df['resized_scaled'].tolist()]\n",
        "X = np.array(X)\n",
        "y = np.array(df['SOH'].tolist()) ##%changed"
      ],
      "metadata": {
        "id": "TAX3dH2DEYFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labeling for stratified random sampling\n",
        "label = df['SOH'].tolist()\n",
        "label_l = []\n",
        "for cnt in range(len(label)):\n",
        "    i = label[cnt]\n",
        "    if i>=1.0 :\n",
        "        lab = '1~'\n",
        "        num = 0\n",
        "    elif 0.98<=i<1.0 :\n",
        "        lab = '0.98~1'\n",
        "        num = 1\n",
        "    elif 0.96<=i<0.98 :\n",
        "        lab = '0.96~0.98'\n",
        "        num = 2\n",
        "    elif 0.94<=i<0.96 :\n",
        "        lab = '0.94~0.96'\n",
        "        num = 3\n",
        "    elif 0.92<=i<0.94 :\n",
        "        lab = '0.92~0.94'\n",
        "        num = 4\n",
        "    elif 0.90<=i<0.92 :\n",
        "        lab = '0.90~0.92'\n",
        "        num = 5\n",
        "\n",
        "    elif 0.88<=i<0.9 :\n",
        "        lab = '0.88~0.9'\n",
        "        num = 6\n",
        "    elif 0.86<=i<0.88 :\n",
        "        lab = '0.86~0.88'\n",
        "        num = 7\n",
        "    elif 0.84<=i<0.86 :\n",
        "        lab = '0.84~0.86'\n",
        "        num = 8\n",
        "    elif 0.82<=i<0.84 :\n",
        "        lab = '0.82~0.84'\n",
        "        num = 9\n",
        "    elif 0.80<=i<0.82 :\n",
        "        lab = '0.80~0.82'\n",
        "        num = 10\n",
        "\n",
        "\n",
        "    elif 0.78<=i<0.8 :\n",
        "        lab = '0.78~0.8'\n",
        "        num = 11\n",
        "    elif 0.76<=i<0.78 :\n",
        "        lab = '0.76~0.78'\n",
        "        num = 12\n",
        "    elif 0.74<=i<0.76 :\n",
        "        lab = '0.74~0.76'\n",
        "        num = 13\n",
        "    elif 0.72<=i<0.74 :\n",
        "        lab = '0.72~0.74'\n",
        "        num = 14\n",
        "    elif 0.70<=i<0.72 :\n",
        "        lab = '0.70~0.72'\n",
        "        num = 15\n",
        "\n",
        "    else:\n",
        "        lab = '~0.7'\n",
        "        num = 16\n",
        "    label_l.append(num)"
      ],
      "metadata": {
        "id": "O5jEpG3REhOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
        "for train_idx, test_idx in sss.split(X, np.array(label_l)):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = np.array(y)[train_idx], np.array(y)[test_idx]\n",
        "    y_valid = np.array(label_l)[test_idx]"
      ],
      "metadata": {
        "id": "pED1rq3-Ei8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
        "for train_idx, test_idx1 in sss.split(X_test, y_valid):\n",
        "    X_valid, X_test_f = X_test[train_idx], X_test[test_idx1]\n",
        "    y_valid, y_test_f = np.array(y_test)[train_idx], np.array(y_test)[test_idx1]\n",
        "X_valid.shape"
      ],
      "metadata": {
        "id": "IgWTx8iGEmlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for i in df['Dataset'][test_idx[test_idx1]].tolist():\n",
        "    if 'LFP' in i:\n",
        "        data_list.append('LFP')\n",
        "    if 'NCA' in i:\n",
        "        data_list.append('NCA')\n",
        "    if 'NMC' in i:\n",
        "        data_list.append('NMC')"
      ],
      "metadata": {
        "id": "mBumRg1mEtvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = X_train\n",
        "x_valid = X_valid\n",
        "x_test = X_test_f\n",
        "x_test.shape"
      ],
      "metadata": {
        "id": "iHiwpfJwEwnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = len(X[0])\n",
        "cols = 3\n",
        "input_shape = (rows, cols, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], rows, cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32') /255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_valid = x_valid.astype('float32')/255.0\n",
        "\n",
        "batch_size = 64\n",
        "print(x_test.shape)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "Hqw5uOCtEzrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(Conv2D(64, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), strides = (1,1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "###"
      ],
      "metadata": {
        "id": "adlhiYOgE2rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "epochs = 5\n",
        "print('start time : ' , start)\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])\n",
        "hist2 = model.fit(x_train, y_train, epochs = epochs, verbose = 1, validation_data = (x_valid, y_valid))"
      ],
      "metadata": {
        "id": "Z7c_NCWlE3uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input, epsilon, data_grad):\n",
        "    # Calculate perturbation by scaling the gradient\n",
        "    pert_out = input + epsilon * data_grad\n",
        "\n",
        "    # Clip the perturbation to ensure it doesn't go beyond reasonable values\n",
        "    pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "\n",
        "    return pert_out\n",
        "\n",
        "def ifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    alpha = epsilon / iterations\n",
        "    pert_out = input\n",
        "    for i in range(iterations):\n",
        "        # Update perturbation by scaling the gradient\n",
        "        pert_out = pert_out + alpha * data_grad\n",
        "        # Clip the perturbation to ensure it doesn't go beyond reasonable values\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "    return pert_out\n",
        "\n",
        "def mifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    decay_factor = 1.0\n",
        "    pert_out = input\n",
        "    alpha = epsilon / iterations\n",
        "    g = 0\n",
        "    for i in range(iterations):\n",
        "        # Update gradient with decay and normalize\n",
        "        g = decay_factor * g + data_grad / tf.norm(data_grad, ord=1)\n",
        "        # Update perturbation by scaling the gradient\n",
        "        pert_out = pert_out + alpha * g\n",
        "        # Clip the perturbation to ensure it doesn't go beyond reasonable values\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "    return pert_out"
      ],
      "metadata": {
        "id": "luF-Zrs1C9wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)\n",
        "print(y_test_f.shape)"
      ],
      "metadata": {
        "id": "wVVN4E9MNCnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hejran modified based on new code"
      ],
      "metadata": {
        "id": "anTAD9b6VBbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, x_test, y_test_f, epsilon, attack):\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for idx in range(len(x_test)):\n",
        "        data, target = x_test[idx], y_test_f[idx]\n",
        "\n",
        "        # Assuming x_test has shape (batch_size, 128, 3, 1)\n",
        "        data = tf.convert_to_tensor(data)\n",
        "        target = tf.convert_to_tensor(target)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            data = tf.Variable(data, trainable=True)\n",
        "            output = model(data)\n",
        "            init_pred = output  # Assuming it's regression, no argmax for regression\n",
        "            if init_pred.numpy() != target.numpy():\n",
        "                continue\n",
        "            loss = tf.keras.losses.mean_squared_error(target, output)\n",
        "\n",
        "        data_grad = tape.gradient(loss, data)\n",
        "\n",
        "        if attack == \"fgsm\":\n",
        "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"ifgsm\":\n",
        "            perturbed_data = ifgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"mifgsm\":\n",
        "            perturbed_data = mifgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        perturbed_data = tf.convert_to_tensor(perturbed_data)\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output  # Assuming it's regression, no argmax for regression\n",
        "\n",
        "        if final_pred.numpy() == target.numpy():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "\n",
        "    final_acc = correct / float(len(x_test))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(x_test), final_acc))\n",
        "\n",
        "    return final_acc, adv_examples\n"
      ],
      "metadata": {
        "id": "Q5auIZcz6h2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIjuHgyFSWY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat GPT solved but wrongly"
      ],
      "metadata": {
        "id": "lJQ0sBzDVObb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, x_test, y_test_f, epsilon, attack):\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for idx in range(len(x_test)):\n",
        "        data, target = x_test[idx], y_test_f[idx]\n",
        "\n",
        "        # Assuming x_test is a list of grayscale images with shape (128, 3, 1)\n",
        "        data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "        data = tf.expand_dims(data, axis=0)  # Add batch dimension\n",
        "        target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            data = tf.Variable(data, trainable=True)\n",
        "            output = model(data)\n",
        "            init_pred = output  # Assuming it's regression, no argmax for regression\n",
        "            if init_pred.numpy() != target.numpy():\n",
        "                continue\n",
        "            loss = tf.keras.losses.mean_squared_error(target, output)\n",
        "\n",
        "        data_grad = tape.gradient(loss, data)\n",
        "\n",
        "        if attack == \"fgsm\":\n",
        "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"ifgsm\":\n",
        "            perturbed_data = ifgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"mifgsm\":\n",
        "            perturbed_data = mifgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        perturbed_data = tf.convert_to_tensor(perturbed_data, dtype=tf.float32)\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output  # Assuming it's regression, no argmax for regression\n",
        "\n",
        "        if final_pred.numpy() == target.numpy():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "\n",
        "    final_acc = correct / float(len(x_test))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(x_test), final_acc))\n",
        "\n",
        "    return final_acc, adv_examples\n"
      ],
      "metadata": {
        "id": "yNMGdpqR20YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "EUOgrbRnOam6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, x_test, y_test_f, epsilon, attack):\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for idx in range(len(x_test)):\n",
        "        data, target = x_test[idx], y_test_f[idx]\n",
        "\n",
        "        data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "        target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            data = tf.Variable(data, trainable=True)\n",
        "            output = model(data)\n",
        "            init_pred = output  # Assuming it's regression, no argmax for regression\n",
        "            if init_pred.numpy() != target.numpy():\n",
        "                continue\n",
        "            loss = tf.keras.losses.mean_squared_error(target, output)\n",
        "\n",
        "        data_grad = tape.gradient(loss, data)\n",
        "\n",
        "        if attack == \"fgsm\":\n",
        "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"ifgsm\":\n",
        "            perturbed_data = ifgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"mifgsm\":\n",
        "            perturbed_data = mifgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        perturbed_data = tf.convert_to_tensor(perturbed_data, dtype=tf.float32)\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output  # Assuming it's regression, no argmax for regression\n",
        "\n",
        "        if final_pred.numpy() == target.numpy():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "\n",
        "    final_acc = correct / float(len(x_test))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(x_test), final_acc))\n",
        "\n",
        "    return final_acc, adv_examples\n"
      ],
      "metadata": {
        "id": "-b9n__s7DYAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0, 0.007, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3]\n",
        "\n",
        "for attack in (\"fgsm\", \"ifgsm\", \"mifgsm\"):\n",
        "    accuracies = []\n",
        "    examples = []\n",
        "    for eps in epsilons:\n",
        "        acc, ex = test(model, x_test, y_test_f, eps, attack)\n",
        "        accuracies.append(acc)\n",
        "        examples.append(ex)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.title(attack)\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "    cnt = 0\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    for i in range(len(epsilons)):\n",
        "        for j in range(len(examples[i])):\n",
        "            cnt += 1\n",
        "            plt.subplot(len(epsilons), len(examples[0]), cnt)\n",
        "            plt.xticks([], [])\n",
        "            plt.yticks([], [])\n",
        "            if j == 0:\n",
        "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "            orig, adv, ex = examples[i][j]\n",
        "            plt.title(\"{} -> {}\".format(orig, adv))\n",
        "            plt.imshow(ex, cmap=\"gray\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "FU6qp8bSFgja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0, 0.007, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3]\n",
        "\n",
        "for attack in (\"fgsm\", \"ifgsm\", \"mifgsm\"):\n",
        "    accuracies = []\n",
        "    examples = []\n",
        "    for eps in epsilons:\n",
        "        acc, ex = test(model, x_test, y_test_f, eps, attack)\n",
        "        accuracies.append(acc)\n",
        "        examples.append(ex)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.title(attack)\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "    cnt = 0\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    for i in range(len(epsilons)):\n",
        "        for j in range(len(examples[i])):\n",
        "            cnt += 1\n",
        "            plt.subplot(len(epsilons), len(examples[0]), cnt)\n",
        "            plt.xticks([], [])\n",
        "            plt.yticks([], [])\n",
        "            if j == 0:\n",
        "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "            orig, adv, ex = examples[i][j]\n",
        "            plt.title(\"{} -> {}\".format(orig, adv))\n",
        "            plt.imshow(ex, cmap=\"gray\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tI3SGiYEDjV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = hist2.history['val_loss']\n",
        "y_loss = hist2.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.legend()\n",
        "plt.title('epoch40_loss')"
      ],
      "metadata": {
        "id": "w6vx0tRiFC7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(x_test, verbose = 0)"
      ],
      "metadata": {
        "id": "db31RcghFTT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "t = []\n",
        "for i in range(len(predict)):\n",
        "    p.append(predict[i])\n",
        "    t.append(y_test_f[i])\n",
        "    #print('predicted SOH: ' , predict[i],',' , 'Answer SOH: '  , y_test[i])\n",
        "\n",
        "plt.scatter(y_test_f, predict)\n",
        "plt.plot(y_test_f, y_test_f,c='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LW7jYE8wFbQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = metrics.r2_score(y_test_f, predict)\n",
        "rmse = metrics.mean_squared_error(y_test_f, predict)**0.5\n",
        "mse = metrics.mean_squared_error(y_test_f, predict)\n",
        "mae = metrics.mean_absolute_error(y_test_f, predict)\n",
        "mape = metrics.mean_absolute_percentage_error(y_test_f,predict)"
      ],
      "metadata": {
        "id": "eGBAoJH8FcJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "dic['r2'] = [r2]\n",
        "dic['rmse'] = [rmse]\n",
        "dic['mse'] = [mse]\n",
        "dic['mae'] = [mae]\n",
        "dic['mape'] = [mape]\n",
        "d = pd.DataFrame(dic)\n",
        "d"
      ],
      "metadata": {
        "id": "rD6G-y4hFgIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input, epsilon, data_grad):\n",
        "    # Calculate perturbation by scaling the gradient\n",
        "    pert_out = input + epsilon * data_grad\n",
        "\n",
        "    # Clip the perturbation to ensure it doesn't go beyond reasonable values\n",
        "    pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "\n",
        "    return pert_out\n",
        "\n",
        "def ifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    alpha = epsilon / iterations\n",
        "    pert_out = input\n",
        "    for i in range(iterations):\n",
        "        # Update perturbation by scaling the gradient\n",
        "        pert_out = pert_out + alpha * data_grad\n",
        "        # Clip the perturbation to ensure it doesn't go beyond reasonable values\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "    return pert_out\n",
        "\n",
        "def mifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    decay_factor = 1.0\n",
        "    pert_out = input\n",
        "    alpha = epsilon / iterations\n",
        "    g = 0\n",
        "    for i in range(iterations):\n",
        "        # Update gradient with decay and normalize\n",
        "        g = decay_factor * g + data_grad / tf.norm(data_grad, ord=1)\n",
        "        # Update perturbation by scaling the gradient\n",
        "        pert_out = pert_out + alpha * g\n",
        "        # Clip the perturbation to ensure it doesn't go beyond reasonable values\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "    return pert_out\n"
      ],
      "metadata": {
        "id": "rHJHu8tM4UBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input, epsilon, data_grad):\n",
        "    pert_out = input + epsilon * tf.sign(data_grad)\n",
        "    pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "    return pert_out\n",
        "\n",
        "def ifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    alpha = epsilon / iterations\n",
        "    pert_out = input\n",
        "    for i in range(iterations - 1):\n",
        "        pert_out = pert_out + alpha * tf.sign(data_grad)\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "        if tf.norm(pert_out - input, ord=float('inf')) > epsilon:\n",
        "            break\n",
        "    return pert_out\n",
        "\n",
        "def mifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    decay_factor = 1.0\n",
        "    pert_out = input\n",
        "    alpha = epsilon / iterations\n",
        "    g = 0\n",
        "    for i in range(iterations - 1):\n",
        "        g = decay_factor * g + data_grad / tf.norm(data_grad, ord=1)\n",
        "        pert_out = pert_out + alpha * tf.sign(g)\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "        if tf.norm(pert_out - input, ord=float('inf')) > epsilon:\n",
        "            break\n",
        "    return pert_out\n",
        "\n",
        "def test(model, x_test, y_test_f, epsilon, attack):\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for idx in range(len(x_test)):\n",
        "        data, target = x_test[idx], y_test_f[idx]\n",
        "\n",
        "        data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "        target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            data = tf.Variable(data, trainable=True)\n",
        "            output = model(data)\n",
        "            init_pred = output  # Assuming it's regression, no argmax for regression\n",
        "            if init_pred.numpy() != target.numpy():\n",
        "                continue\n",
        "            loss = tf.keras.losses.mean_squared_error(target, output)\n",
        "\n",
        "        data_grad = tape.gradient(loss, data)\n",
        "\n",
        "        if attack == \"fgsm\":\n",
        "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"ifgsm\":\n",
        "            perturbed_data = ifgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"mifgsm\":\n",
        "            perturbed_data = mifgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        perturbed_data = tf.convert_to_tensor(perturbed_data, dtype=tf.float32)\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output  # Assuming it's regression, no argmax for regression\n",
        "\n",
        "        if final_pred.numpy() == target.numpy():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "\n",
        "    final_acc = correct / float(len(x_test))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(x_test), final_acc))\n",
        "\n",
        "    return final_acc, adv_examples"
      ],
      "metadata": {
        "id": "PV1-fCEbDjC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fgsm_attack(input, epsilon, data_grad):\n",
        "    pert_out = input + epsilon * tf.sign(data_grad)\n",
        "    pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "    return pert_out\n",
        "\n",
        "def ifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    alpha = epsilon / iterations\n",
        "    pert_out = input\n",
        "    for i in range(iterations - 1):\n",
        "        pert_out = pert_out + alpha * tf.sign(data_grad)\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "        if tf.norm(pert_out - input, ord=float('inf')) > epsilon:\n",
        "            break\n",
        "    return pert_out\n",
        "\n",
        "def mifgsm_attack(input, epsilon, data_grad):\n",
        "    iterations = 10\n",
        "    decay_factor = 1.0\n",
        "    pert_out = input\n",
        "    alpha = epsilon / iterations\n",
        "    g = 0\n",
        "    for i in range(iterations - 1):\n",
        "        g = decay_factor * g + data_grad / tf.norm(data_grad, ord=1)\n",
        "        pert_out = pert_out + alpha * tf.sign(g)\n",
        "        pert_out = tf.clip_by_value(pert_out, 0, 1)\n",
        "        if tf.norm(pert_out - input, ord=float('inf')) > epsilon:\n",
        "            break\n",
        "    return pert_out\n"
      ],
      "metadata": {
        "id": "rsnwpc92GaMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, x_test, y_test, epsilon, attack):\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for idx in range(len(x_test)):\n",
        "        data, target = x_test[idx], y_test_f[idx]\n",
        "\n",
        "        data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "        target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            data = tf.Variable(data, trainable=True)\n",
        "            output = model(data)\n",
        "            init_pred = output  # Assuming it's regression, no argmax for regression\n",
        "            if init_pred.numpy() != target.numpy():\n",
        "                continue\n",
        "            loss = tf.keras.losses.mean_squared_error(target, output)\n",
        "\n",
        "        data_grad = tape.gradient(loss, data)\n",
        "\n",
        "        if attack == \"fgsm\":\n",
        "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"ifgsm\":\n",
        "            perturbed_data = ifgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == \"mifgsm\":\n",
        "            perturbed_data = mifgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        perturbed_data = tf.convert_to_tensor(perturbed_data, dtype=tf.float32)\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output  # Assuming it's regression, no argmax for regression\n",
        "\n",
        "        if final_pred.numpy() == target.numpy():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.numpy().squeeze()\n",
        "                adv_examples.append((init_pred.numpy(), final_pred.numpy(), adv_ex))\n",
        "\n",
        "    final_acc = correct / float(len(x_test))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(x_test), final_acc))\n",
        "\n",
        "    return final_acc, adv_examples\n"
      ],
      "metadata": {
        "id": "sFaGeGD9XqTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_reshaped = x_test.reshape(x_test.shape[0], 128, 3, 1)\n"
      ],
      "metadata": {
        "id": "WDiMxpRQ5jZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0, 0.007, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3]\n",
        "\n",
        "for attack in (\"fgsm\", \"ifgsm\", \"mifgsm\"):\n",
        "    accuracies = []\n",
        "    examples = []\n",
        "    for eps in epsilons:\n",
        "        acc, ex = test(model, x_test_reshaped, y_test_f, eps, attack)\n",
        "        accuracies.append(acc)\n",
        "        examples.append(ex)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.title(attack)\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "    cnt = 0\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    for i in range(len(epsilons)):\n",
        "        for j in range(len(examples[i])):\n",
        "            cnt += 1\n",
        "            plt.subplot(len(epsilons), len(examples[0]), cnt)\n",
        "            plt.xticks([], [])\n",
        "            plt.yticks([], [])\n",
        "            if j == 0:\n",
        "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "            orig, adv, ex = examples[i][j]\n",
        "            plt.title(\"{} -> {}\".format(orig, adv))\n",
        "            plt.imshow(ex, cmap=\"gray\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MJT8cp2F3sYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}