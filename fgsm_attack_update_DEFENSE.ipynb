{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/VMJ/blob/main/fgsm_attack_update_DEFENSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns4t5rH91DGX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D  # Updated import statement\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n-ZYnTS51NQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/T25 (1).csv')"
      ],
      "metadata": {
        "id": "uQlf_Ce41W6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(df['Dataset'].tolist())"
      ],
      "metadata": {
        "id": "MjY81eDq1ciP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ckvYIZRc1h-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [eval(i) for i in df['resized_scaled'].tolist()]\n",
        "X = np.array(X)\n",
        "y = np.array(df['SOH'].tolist()) ##%changed"
      ],
      "metadata": {
        "id": "X0raWgUB1kke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labeling for stratified random sampling\n",
        "label = df['SOH'].tolist()\n",
        "label_l = []\n",
        "for cnt in range(len(label)):\n",
        "    i = label[cnt]\n",
        "    if i>=1.0 :\n",
        "        lab = '1~'\n",
        "        num = 0\n",
        "    elif 0.98<=i<1.0 :\n",
        "        lab = '0.98~1'\n",
        "        num = 1\n",
        "    elif 0.96<=i<0.98 :\n",
        "        lab = '0.96~0.98'\n",
        "        num = 2\n",
        "    elif 0.94<=i<0.96 :\n",
        "        lab = '0.94~0.96'\n",
        "        num = 3\n",
        "    elif 0.92<=i<0.94 :\n",
        "        lab = '0.92~0.94'\n",
        "        num = 4\n",
        "    elif 0.90<=i<0.92 :\n",
        "        lab = '0.90~0.92'\n",
        "        num = 5\n",
        "\n",
        "    elif 0.88<=i<0.9 :\n",
        "        lab = '0.88~0.9'\n",
        "        num = 6\n",
        "    elif 0.86<=i<0.88 :\n",
        "        lab = '0.86~0.88'\n",
        "        num = 7\n",
        "    elif 0.84<=i<0.86 :\n",
        "        lab = '0.84~0.86'\n",
        "        num = 8\n",
        "    elif 0.82<=i<0.84 :\n",
        "        lab = '0.82~0.84'\n",
        "        num = 9\n",
        "    elif 0.80<=i<0.82 :\n",
        "        lab = '0.80~0.82'\n",
        "        num = 10\n",
        "\n",
        "\n",
        "    elif 0.78<=i<0.8 :\n",
        "        lab = '0.78~0.8'\n",
        "        num = 11\n",
        "    elif 0.76<=i<0.78 :\n",
        "        lab = '0.76~0.78'\n",
        "        num = 12\n",
        "    elif 0.74<=i<0.76 :\n",
        "        lab = '0.74~0.76'\n",
        "        num = 13\n",
        "    elif 0.72<=i<0.74 :\n",
        "        lab = '0.72~0.74'\n",
        "        num = 14\n",
        "    elif 0.70<=i<0.72 :\n",
        "        lab = '0.70~0.72'\n",
        "        num = 15\n",
        "\n",
        "    else:\n",
        "        lab = '~0.7'\n",
        "        num = 16\n",
        "    label_l.append(num)"
      ],
      "metadata": {
        "id": "hBPXjryt1slu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
        "for train_idx, test_idx in sss.split(X, np.array(label_l)):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = np.array(y)[train_idx], np.array(y)[test_idx]\n",
        "    y_valid = np.array(label_l)[test_idx]"
      ],
      "metadata": {
        "id": "HKuuEx9laE0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
        "for train_idx, test_idx1 in sss.split(X_test, y_valid):\n",
        "    X_valid, X_test_f = X_test[train_idx], X_test[test_idx1]\n",
        "    y_valid, y_test_f = np.array(y_test)[train_idx], np.array(y_test)[test_idx1]\n",
        "X_valid.shape\n"
      ],
      "metadata": {
        "id": "eErr4p7MlqeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for i in df['Dataset'][test_idx[test_idx1]].tolist():\n",
        "    if 'LFP' in i:\n",
        "        data_list.append('LFP')\n",
        "    if 'NCA' in i:\n",
        "        data_list.append('NCA')\n",
        "    if 'NMC' in i:\n",
        "        data_list.append('NMC')"
      ],
      "metadata": {
        "id": "qXA634s1l40g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = X_train\n",
        "x_valid = X_valid\n",
        "x_test = X_test_f\n",
        "x_test.shape\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "MkNZ5HYal71g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = len(X[0])\n",
        "cols = 3\n",
        "input_shape = (rows, cols, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], rows, cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32') /255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_valid = x_valid.astype('float32')/255.0\n",
        "\n",
        "batch_size = 64\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "5UGCykMal_Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "za-7j_AMN8qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###student model model with additional feature extraction branch\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(Conv2D(64, kernel_size = (2,2), strides = (1,1), padding = 'same', activation = 'relu', input_shape = input_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), strides = (1,1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "###"
      ],
      "metadata": {
        "id": "xPrBzPu5-o_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "epochs = 5\n",
        "print('start time : ' , start)\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])\n",
        "hist2 = model.fit(x_train, y_train, epochs = epochs, verbose = 1, validation_data = (x_valid, y_valid))"
      ],
      "metadata": {
        "id": "0W5AoQGI_49S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = hist2.history['val_loss']\n",
        "y_loss = hist2.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.legend()\n",
        "plt.title('epoch40_loss')"
      ],
      "metadata": {
        "id": "gV7i8S7m2w7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fgsm_perturb(x_test, epsilon):\n",
        "    x_test_tf = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x_test_tf)\n",
        "        output = model(x_test_tf)\n",
        "        loss = tf.keras.losses.mean_squared_error(y_test_f, output)\n",
        "    # Calculate gradient of the loss with respect to the input\n",
        "    gradient = tape.gradient(loss, x_test_tf)\n",
        "\n",
        "    # Create perturbation using the sign of the gradient\n",
        "    perturbation = epsilon * tf.sign(gradient)\n",
        "\n",
        "    # Apply perturbation to the input data\n",
        "    perturbed_data = x_test_tf + perturbation\n",
        "\n",
        "    return perturbed_data.numpy()\n",
        "\n",
        "# Assuming model and labels are defined elsewhere\n",
        "#x_test_ad = fgsm_perturb(x_test, 0.01)\n",
        "#x_test_ad.shape\n",
        "x_test_ad = fgsm_perturb(x_test, 0.02)\n",
        "#print(\"Original input:\", x_test[0])\n",
        "#print(\"Perturbed input:\", x_test_ad[0])\n",
        "\n",
        "# Evaluate the model on the original and perturbed data\n",
        "original_predictions = model.predict(x_test, verbose = 0)\n",
        "perturbed_predictions = model.predict(x_test_ad, verbose = 0)\n",
        "\n",
        "# Compare predictions\n",
        "#print(\"Original predictions:\", original_predictions[0])\n",
        "#print(\"Perturbed predictions:\", perturbed_predictions[0])\n",
        "\n",
        "# Continue with plotting or other analysis"
      ],
      "metadata": {
        "id": "pFNNEskhmPLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(x_test_ad, verbose = 0)\n"
      ],
      "metadata": {
        "id": "88O3lI3d6Vi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "t = []\n",
        "for i in range(len(predict)):\n",
        "    p.append(predict[i])\n",
        "    t.append(y_test_f[i])\n",
        "    #print('predicted SOH: ' , predict[i],',' , 'Answer SOH: '  , y_test[i])\n",
        "\n",
        "plt.scatter(y_test_f, predict)\n",
        "plt.plot(y_test_f, y_test_f,c='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3xXBm0LF2zqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = metrics.r2_score(y_test_f, predict)\n",
        "rmse = metrics.mean_squared_error(y_test_f, predict)**0.5\n",
        "mse = metrics.mean_squared_error(y_test_f, predict)\n",
        "mae = metrics.mean_absolute_error(y_test_f, predict)\n",
        "mape = metrics.mean_absolute_percentage_error(y_test_f,predict)"
      ],
      "metadata": {
        "id": "RC1hrOQu24CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "dic['r2'] = [r2]\n",
        "dic['rmse'] = [rmse]\n",
        "dic['mse'] = [mse]\n",
        "dic['mae'] = [mae]\n",
        "dic['mape'] = [mape]\n",
        "d = pd.DataFrame(dic)\n",
        "d"
      ],
      "metadata": {
        "id": "L04LdKVM26on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Defense"
      ],
      "metadata": {
        "id": "yswOGqtcolbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "# Assuming x_train, y_train, x_valid, y_valid are your training and validation data\n",
        "\n",
        "# Original teacher model definition\n",
        "teacher_model = Sequential()\n",
        "teacher_model.add(Conv2D(32, kernel_size=(2, 2), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
        "teacher_model.add(Conv2D(64, kernel_size=(2, 2), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
        "teacher_model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "teacher_model.add(Flatten())\n",
        "teacher_model.add(Dense(64, activation='relu', name='feature_extraction'))\n",
        "teacher_model.add(Dense(1))\n",
        "teacher_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "# Original student model definition\n",
        "student_model = Sequential()\n",
        "student_model.add(Conv2D(32, kernel_size=(2, 2), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
        "student_model.add(Conv2D(64, kernel_size=(2, 2), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
        "student_model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "student_model.add(Flatten())\n",
        "student_model.add(Dense(64, activation='relu', name='feature_extraction'))\n",
        "student_model.add(Dense(1))\n",
        "student_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "# Create a new model to extract features from the 'feature_extraction' layer\n",
        "feature_extraction_model_teacher = Model(inputs=teacher_model.input, outputs=teacher_model.get_layer('feature_extraction').output)\n",
        "feature_extraction_model_student = Model(inputs=student_model.input, outputs=student_model.get_layer('feature_extraction').output)\n",
        "\n",
        "# Define custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Extract features from the 'feature_extraction' layer for both teacher and student\n",
        "    features_teacher = feature_extraction_model_teacher(x_train)\n",
        "    features_student = feature_extraction_model_student(x_train)\n",
        "\n",
        "    # Compute MSE between features of teacher and student\n",
        "    mse_feature = tf.keras.losses.MeanSquaredError()(features_teacher, features_student)\n",
        "\n",
        "    # Compute absolute error between the output of teacher and student\n",
        "    abs_error_output = tf.keras.losses.MeanAbsoluteError()(teacher_model(x_train), student_model(x_train))\n",
        "\n",
        "    # You can adjust the weights (alpha and beta) based on your preference\n",
        "    alpha = 1\n",
        "    beta = 1\n",
        "\n",
        "    # Combined loss\n",
        "    total_loss = alpha * mse_feature + beta * abs_error_output\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "# Compile and train the student model with the custom loss function\n",
        "student_model.compile(loss=custom_loss, optimizer='adam', metrics=['mse'])\n",
        "epochs = 2\n",
        "history = student_model.fit(x_train, y_train, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid))\n"
      ],
      "metadata": {
        "id": "TLjTqcc8Me17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = hist2.history['val_loss']\n",
        "y_loss = hist2.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.legend()\n",
        "plt.title('epoch40_loss')"
      ],
      "metadata": {
        "id": "Gjxnc4QIZwGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_perturb(x_test, epsilon):\n",
        "    x_test_tf = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x_test_tf)\n",
        "        output = teacher_model(x_test_tf)\n",
        "        loss = tf.keras.losses.mean_squared_error(y_test_f, output)\n",
        "    # Calculate gradient of the loss with respect to the input\n",
        "    gradient = tape.gradient(loss, x_test_tf)\n",
        "\n",
        "    # Create perturbation using the sign of the gradient\n",
        "    perturbation = epsilon * tf.sign(gradient)\n",
        "\n",
        "    # Apply perturbation to the input data\n",
        "    perturbed_data = x_test_tf + perturbation\n",
        "\n",
        "    return perturbed_data.numpy()\n",
        "\n",
        "# Assuming model and labels are defined elsewhere\n",
        "#x_test_ad = fgsm_perturb(x_test, 0.01)\n",
        "#x_test_ad.shape\n",
        "x_test_ad = fgsm_perturb(x_test, 0.02)\n",
        "#print(\"Original input:\", x_test[0])\n",
        "#print(\"Perturbed input:\", x_test_ad[0])\n",
        "\n",
        "# Evaluate the model on the original and perturbed data\n",
        "original_predictions = teacher_model.predict(x_test, verbose = 0)\n",
        "perturbed_predictions = teacher_model.predict(x_test_ad, verbose = 0)\n",
        "\n",
        "# Compare predictions\n",
        "#print(\"Original predictions:\", original_predictions[0])\n",
        "#print(\"Perturbed predictions:\", perturbed_predictions[0])\n",
        "\n",
        "# Continue with plotting or other analysis"
      ],
      "metadata": {
        "id": "bePZTQxjZ7ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict =  model.predict(x_test, verbose = 0)"
      ],
      "metadata": {
        "id": "XTsYem767ELd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "t = []\n",
        "for i in range(len(predict)):\n",
        "    p.append(predict[i])\n",
        "    t.append(y_test_f[i])\n",
        "    #print('predicted SOH: ' , predict[i],',' , 'Answer SOH: '  , y_test[i])\n",
        "\n",
        "plt.scatter(y_test_f, predict)\n",
        "plt.plot(y_test_f, y_test_f,c='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iFpyDO8g7LzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = metrics.r2_score(y_test_f, predict)\n",
        "rmse = metrics.mean_squared_error(y_test_f, predict)**0.5\n",
        "mse = metrics.mean_squared_error(y_test_f, predict)\n",
        "mae = metrics.mean_absolute_error(y_test_f, predict)\n",
        "mape = metrics.mean_absolute_percentage_error(y_test_f,predict)"
      ],
      "metadata": {
        "id": "N1tkOXqe7PFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "dic['r2'] = [r2]\n",
        "dic['rmse'] = [rmse]\n",
        "dic['mse'] = [mse]\n",
        "dic['mae'] = [mae]\n",
        "dic['mape'] = [mape]\n",
        "d = pd.DataFrame(dic)"
      ],
      "metadata": {
        "id": "cu17nfzk7SDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "gjbdDmTq7U6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}