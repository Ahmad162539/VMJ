{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJq44G3ZU+/3zAG4LudBkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/VMJ/blob/main/New%20Adversary%20attack%20on%20MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrJccHMDIte0",
        "outputId": "cacd6782-4efd-4311-b77b-2264f0271ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "10000\n",
            "CNN_Model(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
            "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n",
            "Fitting the model...\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled1.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1DOEfZL2C11tGRuGhb3-VwdJjqcwNzz9i\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms,datasets\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,), (1.0,))])\n",
        "dataset = datasets.MNIST(root = './data', train=True, transform = transform, download=True)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
        "test_set = datasets.MNIST(root = './data', train=False, transform = transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set,batch_size=1,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1,shuffle=True)\n",
        "\n",
        "print(len(train_set))\n",
        "\n",
        "print(len(test_set))\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "> <h1>Model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class CNN_Model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN_Model, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "    self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "    self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc1(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.fc3(out)\n",
        "    out = F.log_softmax(out, dim=1)\n",
        "\n",
        "    return out\n",
        "\n",
        "use_cuda=True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "model = CNN_Model().to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "criterion = nn.NLLLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "print(model)\n",
        "\n",
        "\"\"\"<h1>Fitting the original model to test it's accuracy\"\"\"\n",
        "\n",
        "data_loader = {'train':train_loader,'val':val_loader}\n",
        "print(\"Fitting the model...\")\n",
        "train_loss,val_loss=[],[]\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    loss_per_epoch,val_loss_per_epoch=0,0\n",
        "    for phase in ('train','val'):\n",
        "      for i,data in enumerate(data_loader[phase]):\n",
        "        input,label  = data[0].to(device),data[1].to(device)\n",
        "        output = model(input)\n",
        "        loss = criterion(output,label)\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          loss_per_epoch+=loss.item()\n",
        "        else:\n",
        "          val_loss_per_epoch+=loss.item()\n",
        "\n",
        "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
        "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
        "    train_loss.append(loss_per_epoch/len(train_loader))\n",
        "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
        "\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "plt.plot(np.arange(1,3), train_loss, \"*-\",label=\"Loss\")\n",
        "plt.plot(np.arange(1,3), val_loss,\"o-\",label=\"Val Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\"\"\"<h1>Attacks definitation\"\"\"\n",
        "\n",
        "def fgsm_attack(input_data,epsilon,data_grad):\n",
        "  ###applying the formulae for the input data\n",
        "  perturbated_image = input_data + epsilon*data_grad.sign()\n",
        "  perturbated_image = torch.clamp(perturbated_image, 0, 1)\n",
        "  return perturbated_image\n",
        "\n",
        "def ifgsm_attack(input_data,epsilon,data_grad):\n",
        "  iterations = 5\n",
        "  constant = epsilon/iterations\n",
        "  perturbated_out = input_data\n",
        "  for i in range(iterations-1):\n",
        "    perturbated_out = perturbated_out + constant*data_grad.sign()\n",
        "    perturbated_out = torch.clamp(perturbated_out, 0, 1)\n",
        "    if torch.norm((perturbated_out-input_data),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return perturbated_out\n",
        "\n",
        "def test(model,device,test_loader,epsilon,attack):\n",
        "  correct = 0\n",
        "\n",
        "  for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      data.requires_grad = True\n",
        "      output = model(data)\n",
        "      init_pred = output.max(1, keepdim=True)[1]\n",
        "      if init_pred.item() != target.item():\n",
        "          continue\n",
        "      ####loss is calculated using negative liklihood\n",
        "      loss = F.nll_loss(output, target)\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "      data_grad = data.grad.data\n",
        "\n",
        "      if attack == \"fgsm\":\n",
        "        perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
        "      elif attack == \"ifgsm\":\n",
        "        perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
        "\n",
        "      output = model(perturbed_data)\n",
        "      final_pred = output.max(1, keepdim=True)[1]\n",
        "      if final_pred.item() == target.item():\n",
        "          correct += 1\n",
        "\n",
        "  final_accuracy = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {}\".format(epsilon, final_accuracy))\n",
        "\n",
        "  return final_accuracy\n",
        "\n",
        "epsilons = [0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3,0.5]\n",
        "for attack in (\"fgsm\",\"ifgsm\"):\n",
        "  accuracies = []\n",
        "  for eps in epsilons:\n",
        "      accuracy = test(model, device,test_loader,eps,attack)\n",
        "      accuracies.append(accuracy)\n",
        "\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.plot(epsilons, accuracies, \"*-\")\n",
        "  plt.title(attack)\n",
        "  plt.xlabel(\"Epsilon\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"<h1>Implementing Defense\"\"\"\n",
        "\n",
        "class CNN_Model_second_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN_Model_second_model, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "    self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "    self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc1(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "def fit(model,device,optimizer,scheduler,criterion,train_loader,val_loader,Temp,epochs):\n",
        "  data_loader = {'train':train_loader,'val':val_loader}\n",
        "  print(\"Fitting the model...\")\n",
        "  train_loss,val_loss=[],[]\n",
        "  for epoch in range(epochs):\n",
        "    loss_per_epoch,val_loss_per_epoch=0,0\n",
        "    for phase in ('train','val'):\n",
        "      for i,data in enumerate(data_loader[phase]):\n",
        "        input,label  = data[0].to(device),data[1].to(device)\n",
        "        output = model(input)\n",
        "        output = F.log_softmax(output/Temp,dim=1)\n",
        "        loss = criterion(output,label)\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          loss_per_epoch+=loss.item()\n",
        "        else:\n",
        "          val_loss_per_epoch+=loss.item()\n",
        "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
        "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
        "    train_loss.append(loss_per_epoch/len(train_loader))\n",
        "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
        "  return train_loss,val_loss\n",
        "\n",
        "def test(model,device,test_loader,epsilon,Temp,attack):\n",
        "  correct=0\n",
        "\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data.requires_grad = True\n",
        "    output = model(data)\n",
        "    output = F.log_softmax(output/Temp,dim=1)\n",
        "    init_pred = output.max(1, keepdim=True)[1]\n",
        "    if init_pred.item() != target.item():\n",
        "        continue\n",
        "    loss = F.nll_loss(output, target)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    if attack == \"fgsm\":\n",
        "      perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
        "    elif attack == \"ifgsm\":\n",
        "      perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
        "\n",
        "    output = model(perturbed_data)\n",
        "    final_pred = output.max(1, keepdim=True)[1]\n",
        "    if final_pred.item() == target.item():\n",
        "        correct += 1\n",
        "\n",
        "  final_accuracy = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {}\".format(epsilon, final_accuracy))\n",
        "\n",
        "  return final_accuracy\n",
        "\n",
        "def defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons):\n",
        "\n",
        "  modelF = CNN_Model().to(device)\n",
        "  optimizerF = optim.Adam(modelF.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "  schedulerF = optim.lr_scheduler.ReduceLROnPlateau(optimizerF, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "  modelF1 = CNN_Model_second_model().to(device)\n",
        "  optimizerF1 = optim.Adam(modelF1.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "  schedulerF1 = optim.lr_scheduler.ReduceLROnPlateau(optimizerF1, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  lossF,val_lossF=fit(modelF,device,optimizerF,schedulerF,criterion,train_loader,val_loader,Temp,epochs)\n",
        "  fig = plt.figure(figsize=(7,7))\n",
        "  plt.plot(np.arange(1,epochs+1), lossF, \"*-\",label=\"Loss\")\n",
        "  plt.plot(np.arange(1,epochs+1), val_lossF,\"o-\",label=\"Val Loss\")\n",
        "  plt.title(\"first network\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  for data in train_loader:\n",
        "    input, label  = data[0].to(device),data[1].to(device)\n",
        "    softlabel  = F.log_softmax(modelF(input),dim=1)\n",
        "    data[1] = softlabel\n",
        "\n",
        "  lossF1,val_lossF1=fit(modelF1,device,optimizerF1,schedulerF1,criterion,train_loader,val_loader,Temp,epochs)\n",
        "  fig = plt.figure(figsize=(7,7))\n",
        "  plt.plot(np.arange(1,epochs+1), lossF1, \"*-\",label=\"Loss\")\n",
        "  plt.plot(np.arange(1,epochs+1), val_lossF1,\"o-\",label=\"Val Loss\")\n",
        "  plt.title(\"second network\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  model = CNN_Model_second_model().to(device)\n",
        "  model.load_state_dict(modelF1.state_dict())\n",
        "  for attack in (\"fgsm\",\"ifgsm\"):\n",
        "    accuracies = []\n",
        "    for eps in epsilons:\n",
        "        accuracy = test(model,device,test_loader,eps,1,\"fgsm\")\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.title(attack)\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "Temp=20\n",
        "epochs=10\n",
        "epsilons=[0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3,0.5]\n",
        "defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons)"
      ]
    }
  ]
}